{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Résumé de l'article : \n",
        "\n",
        "Le papier discute le sujet de l’augmentation de données pour achever des résultats plus élevé que les models de base (des models sans augmentation de données).\n",
        "\n",
        "Le problème avec les jeux de données existants c’est qu’ils sont restreints à un nombre de domaine limité, ce qui pénalise les models.\n",
        "\n",
        "Des solutions ont été déjà proposé dans l’état de l’art comme la continuité d’entrainement sur le domaine cible ou bien l’adaptation du corpus original par augmentation (ajout de bruit, cropping..), insertion aléatoire des mots. La méthode suivie dans l’article c’est celle de (Dai & Adel, 2020), le remplacement de mentions. Un des avantages de cette méthode par rapport aux autres, c’est sa simplicité et ne demande pas d’annotation.\n",
        "\n",
        "**Idée de la méthode** : Remplacement d’une mention et ses mentions équivalentes par une autre entité de même type récupérée d’une liste prédéfinie au début.\n",
        "\n",
        "Entité sur la quelle l’étude s’est concentré c’est PERSONNE.\n",
        "\n",
        "L’entrainement s’est fait sur 5 configurations dont une sans augmentation de données.\n",
        "\n",
        "Entraînement avec augmentation interne : où on utilise notre version “interne” des données en appliquant la méthode d’augmentation\n",
        "\n",
        "Entraînement avec augmentation externe hors-domaine : où on utilise des données externes.\n",
        "\n",
        "Entraînement avec augmentation externe intra-domaine : les données viennent de l’extérieur mais les entités nommées visées sont un peu different (dans l’article c’était nom personne dans le base, et les noms Fantasy dans l’externe)\n",
        "\n",
        "Entraînement avec augmentation parfaite : on utilise ici des données externes mais contenant les entités nommées dans le jeu de données de base.\n",
        "Les taux d’augmentation choisis sont : 5%, 10%, 50% et 100%\n",
        "\n",
        "**Résultats et limites :**\n",
        "\n",
        "3 métriques d’évaluation ont été observés, la précision, Rappel et le F1-score, un calcul des moyennes est fait sur les métriques mentionnés sur 25 entraînements.\n",
        "On constate des gains pour le Rappel et le F1-score sur presque tout les types d’augmentation spécialement sur l’augmentation externe intera-domaine (fantasy) mais une précision qui ne s’améliore pas en incrémentant le taux d’augmentation.\n",
        "Le résultat reste limité à un genre d’entités nommées (PERSONNE), et domain-specific.  De nouveaux domaines et d’autres types de combinaisons sont à explorés.\n"
      ],
      "metadata": {
        "id": "YDxpazcCfL0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Dbg6xD8vfz",
        "outputId": "ab84966b-7646-44cb-8ee3-f5c8db44cf82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ddaugNER'...\n",
            "remote: Enumerating objects: 365, done.\u001b[K\n",
            "remote: Counting objects: 100% (365/365), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 365 (delta 204), reused 302 (delta 147), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (365/365), 1.11 MiB | 8.92 MiB/s, done.\n",
            "Resolving deltas: 100% (204/204), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CompNet/ddaugNER.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ddaugNER/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6B0OL-s9EOB",
        "outputId": "ea56ccbb-0c44-49ab-f067-2e4d8fe7b748"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ddaugNER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "#3.9.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGNQ16AU9GGu",
        "outputId": "d4067796-3381-4c54-9d58-23fcd60d2fdf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [1 In\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Wait\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,561 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,066 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,259 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,336 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,300 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,492 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [93.6 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [23.9 kB]\n",
            "Fetched 13.4 MB in 2s (5,533 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib python3.9-minimal\n",
            "Suggested packages:\n",
            "  python3.9-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib python3.9 python3.9-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 4,917 kB of archives.\n",
            "After this operation, 19.1 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.9-minimal amd64 3.9.15-1+bionic1 [805 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9-minimal amd64 3.9.15-1+bionic1 [1,938 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.9-stdlib amd64 3.9.15-1+bionic1 [1,680 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9 amd64 3.9.15-1+bionic1 [494 kB]\n",
            "Fetched 4,917 kB in 4s (1,173 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.9-minimal_3.9.15-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.15-1+bionic1) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../python3.9-minimal_3.9.15-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.15-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.9-stdlib_3.9.15-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.15-1+bionic1) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../python3.9_3.9.15-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.15-1+bionic1) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.15-1+bionic1) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.15-1+bionic1) ...\n",
            "Setting up python3.9-minimal (3.9.15-1+bionic1) ...\n",
            "Setting up python3.9 (3.9.15-1+bionic1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.9.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3-pip\n",
        "!sudo apt install python3.9-distutils\n",
        "!python -m pip install --upgrade pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIDdheKk9JHp",
        "outputId": "f3700ba0-7192-4c05-8a68-57e69bb5b476"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
            "  python3-wheel python3-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
            "  python3-six python3-wheel python3-xdg\n",
            "0 upgraded, 15 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 2,882 kB of archives.\n",
            "After this operation, 8,886 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Fetched 2,882 kB in 2s (1,685 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 124630 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "/usr/lib/python3.9/subprocess.py:935: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python3.9-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.9-distutils python3.9-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 315 kB of archives.\n",
            "After this operation, 1,234 kB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9-lib2to3 all 3.9.15-1+bionic1 [125 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9-distutils all 3.9.15-1+bionic1 [190 kB]\n",
            "Fetched 315 kB in 1s (232 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "(Reading database ... 125310 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.9-lib2to3_3.9.15-1+bionic1_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.15-1+bionic1) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../python3.9-distutils_3.9.15-1+bionic1_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.15-1+bionic1) ...\n",
            "Setting up python3.9-lib2to3 (3.9.15-1+bionic1) ...\n",
            "Setting up python3.9-distutils (3.9.15-1+bionic1) ...\n",
            "Collecting pip\n",
            "  Downloading https://files.pythonhosted.org/packages/09/bd/2410905c76ee14c62baf69e3f4aa780226c1bbfc9485731ad018e35b0cb5/pip-22.3.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 698kB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 9.0.1\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "Successfully installed pip-22.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install poetry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kimszcH29PGv",
        "outputId": "9afe8c90-ab40-45d7-f559-4ca57af4dc0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting poetry\n",
            "  Downloading poetry-1.2.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cleo<2.0.0,>=1.0.0a5\n",
            "  Downloading cleo-1.0.0a5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect<5.0.0,>=4.7.0\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema<5.0.0,>=4.10.0\n",
            "  Downloading jsonschema-4.17.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keyring>=21.2.0\n",
            "  Downloading keyring-23.11.0-py3-none-any.whl (36 kB)\n",
            "Collecting tomlkit!=0.11.2,!=0.11.3,<1.0.0,>=0.11.1\n",
            "  Downloading tomlkit-0.11.6-py3-none-any.whl (35 kB)\n",
            "Collecting requests<3.0,>=2.18\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html5lib<2.0,>=1.0\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.26.0\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.4\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv!=20.4.5,!=20.4.6,>=20.4.3\n",
            "  Downloading virtualenv-20.16.7-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachecontrol[filecache]<0.13.0,>=0.12.9\n",
            "  Downloading CacheControl-0.12.11-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pkginfo<2.0,>=1.5\n",
            "  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\n",
            "Collecting crashtest<0.4.0,>=0.3.0\n",
            "  Downloading crashtest-0.3.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting poetry-plugin-export<2.0.0,>=1.1.2\n",
            "  Downloading poetry_plugin_export-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting cachy<0.4.0,>=0.3.0\n",
            "  Downloading cachy-0.3.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting importlib-metadata<5.0,>=4.4\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting platformdirs<3.0.0,>=2.5.2\n",
            "  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n",
            "Collecting dulwich<0.21.0,>=0.20.46\n",
            "  Downloading dulwich-0.20.50-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<0.10.0,>=0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting poetry-core==1.3.2\n",
            "  Downloading poetry_core-1.3.2-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.3/531.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shellingham<2.0,>=1.5\n",
            "  Downloading shellingham-1.5.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting msgpack>=0.5.2\n",
            "  Downloading msgpack-1.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lockfile>=0.9\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting pylev<2.0.0,>=1.3.0\n",
            "  Downloading pylev-1.4.0-py2.py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from html5lib<2.0,>=1.0->poetry) (1.11.0)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.4.0\n",
            "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
            "Collecting pyparsing!=3.0.5,>=2.0.2\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0,>=2.18->poetry) (2.6)\n",
            "Collecting filelock<4,>=3.4.1\n",
            "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.0 in /usr/lib/python3/dist-packages (from SecretStorage>=3.2->keyring>=21.2.0->poetry) (2.1.4)\n",
            "Collecting more-itertools\n",
            "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: webencodings, pylev, ptyprocess, msgpack, lockfile, distlib, zipp, urllib3, tomlkit, shellingham, pyrsistent, pyparsing, poetry-core, platformdirs, pkginfo, pexpect, more-itertools, jeepney, html5lib, filelock, crashtest, charset-normalizer, certifi, cachy, attrs, virtualenv, SecretStorage, requests, packaging, jsonschema, jaraco.classes, importlib-metadata, dulwich, cleo, requests-toolbelt, keyring, cachecontrol, poetry-plugin-export, poetry\n",
            "  Attempting uninstall: SecretStorage\n",
            "    Found existing installation: SecretStorage 2.3.1\n",
            "    Uninstalling SecretStorage-2.3.1:\n",
            "      Successfully uninstalled SecretStorage-2.3.1\n",
            "  Attempting uninstall: keyring\n",
            "    Found existing installation: keyring 10.6.0\n",
            "    Uninstalling keyring-10.6.0:\n",
            "      Successfully uninstalled keyring-10.6.0\n",
            "Successfully installed SecretStorage-3.3.3 attrs-22.1.0 cachecontrol-0.12.11 cachy-0.3.0 certifi-2022.9.24 charset-normalizer-2.1.1 cleo-1.0.0a5 crashtest-0.3.1 distlib-0.3.6 dulwich-0.20.50 filelock-3.8.0 html5lib-1.1 importlib-metadata-4.13.0 jaraco.classes-3.2.3 jeepney-0.8.0 jsonschema-4.17.0 keyring-23.11.0 lockfile-0.12.2 more-itertools-9.0.0 msgpack-1.0.4 packaging-21.3 pexpect-4.8.0 pkginfo-1.8.3 platformdirs-2.5.4 poetry-1.2.2 poetry-core-1.3.2 poetry-plugin-export-1.2.0 ptyprocess-0.7.0 pylev-1.4.0 pyparsing-3.0.9 pyrsistent-0.19.2 requests-2.28.1 requests-toolbelt-0.9.1 shellingham-1.5.0 tomlkit-0.11.6 urllib3-1.26.12 virtualenv-20.16.7 webencodings-0.5.1 zipp-3.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "pexpect"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GUiG8r-9cDr",
        "outputId": "76752280-6bcb-40f2-bcfe-c34e414cf6fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alabaster==0.7.12\n",
            "  Downloading alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n",
            "Collecting attrs==21.4.0\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting babel==2.10.3\n",
            "  Downloading Babel-2.10.3-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2021.10.8\n",
            "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer==2.0.11\n",
            "  Downloading charset_normalizer-2.0.11-py3-none-any.whl (39 kB)\n",
            "Collecting click==8.0.3\n",
            "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama==0.4.5\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting commonmark==0.9.1\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m442.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.11.0\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting docutils==0.19\n",
            "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock==3.4.2\n",
            "  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
            "Collecting fonttools==4.29.1\n",
            "  Downloading fonttools-4.29.1-py3-none-any.whl (895 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.5/895.5 kB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.4.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hypothesis==6.36.1\n",
            "  Downloading hypothesis-6.36.1-py3-none-any.whl (376 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==3.3\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imagesize==1.4.1\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting importlib-metadata==5.0.0\n",
            "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting jinja2==3.1.2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib==1.1.0\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver==1.3.2\n",
            "  Downloading kiwisolver-1.3.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markupsafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting more-itertools==8.12.0\n",
            "  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nameparser==1.1.1\n",
            "  Downloading nameparser-1.1.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting nltk==3.7\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.22.2\n",
            "  Downloading numpy-1.22.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging==21.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (21.3)\n",
            "Collecting pillow==9.0.1\n",
            "  Downloading Pillow-9.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments==2.13.0\n",
            "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing==3.0.7\n",
            "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil==2.8.2\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz==2022.4\n",
            "  Downloading pytz-2022.4-py2.py3-none-any.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.8/500.8 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml==6.0\n",
            "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.8/661.8 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex==2022.1.18\n",
            "  Downloading regex-2022.1.18-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.2/763.2 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.27.1\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich==11.1.0\n",
            "  Downloading rich-11.1.0-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.47\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.0.2\n",
            "  Downloading scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.1\n",
            "  Downloading scipy-1.6.1-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval==1.2.2\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXhUsRaV91L1",
        "outputId": "d0982358-3608-4772-c976-f9daaf0c6e02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rich"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSMspPWh91c-",
        "outputId": "a755ef49-bf26-4530-bfe7-d58c5ab5adaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rich\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "Collecting pygments<3.0.0,>=2.6.0\n",
            "  Using cached Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: commonmark, pygments, rich\n",
            "Successfully installed commonmark-0.9.1 pygments-2.13.0 rich-12.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp8tMcaO93Dn",
        "outputId": "61d5ef2f-db08-468f-8813-e5bd14111af3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_PCK53U94Tl",
        "outputId": "e7d91e1a-22d6-4dc5-e76e-bdab7f734427"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch\n",
            "  Downloading torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1112711168 bytes == 0x37b94000 @  0x7f7b6d46d615 0x60596b 0x543df1 0x543f6b 0x54403b 0x55c314 0x4ae709 0x5bcb62 0x5f4594 0x4ae709 0x5bcb62 0x5f4594 0x4ae709 0x5bcb62 0x5f4594 0x4ae709 0x5bcb62 0x5f4594 0x4ae709 0x5bcb62 0x5f4594 0x4ae709 0x5f44c4 0x4ae709 0x5bcb62 0x5f4604 0x4ae642 0x5bcb62 0x5f4594 0x4ae709 0x5bcb62\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.30.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (39.0.1)\n",
            "Installing collected packages: typing-extensions, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0 typing-extensions-4.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup_dekker_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEE9pQiz950t",
        "outputId": "2c379574-faf3-48da-c383-6dd29369bbb3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Out-with-the-Old-and-in-with-the-Novel'...\n",
            "remote: Enumerating objects: 788, done.\u001b[K\n",
            "remote: Total 788 (delta 0), reused 0 (delta 0), pack-reused 788\u001b[K\n",
            "Receiving objects: 100% (788/788), 18.88 MiB | 26.42 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n",
            "Book \u001b[32m'TheWheelOfTime'\u001b[0m already has NER tags. Skipping\u001b[33m...\u001b[0m\n",
            "Book \u001b[32m'StormFront'\u001b[0m already has NER tags. Skipping\u001b[33m...\u001b[0m\n",
            "Book \u001b[32m'TheWheelOfTime'\u001b[0m already has NER tags. Skipping\u001b[33m...\u001b[0m\n",
            "Book \u001b[32m'StormFront'\u001b[0m already has NER tags. Skipping\u001b[33m...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQn0RYSH97Jl",
        "outputId": "7da75cd3-6df8-411b-9114-19caa32c6ae5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/ddaugNER/train.py\", line 2, in <module>\n",
            "    from transformers import BertForTokenClassification\n",
            "ModuleNotFoundError: No module named 'transformers'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t469pe8w99TE",
        "outputId": "56a31f86-87cc-4c27-f9b8-083843263363"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy>=1.14.0\n",
            "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=0.21.3\n",
            "  Downloading scikit_learn-1.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.3.2\n",
            "  Downloading scipy-1.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=1.0.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=17590 sha256=3117a35d1b0fcb64b2888a6d0038b6ec9fac6a32f8e2b7acdd5c7cf6e4f1a0fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/d6/00/1ccfd5a7466a94774e00022683d4b028836032dfb85007822b\n",
            "Successfully built seqeval\n",
            "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn, seqeval\n",
            "Successfully installed joblib-1.2.0 numpy-1.23.5 scikit-learn-1.1.3 scipy-1.9.3 seqeval-1.2.2 threadpoolctl-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade setuptools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZCzF3NO-fXZ",
        "outputId": "b1974801-9c0c-468f-d553-8ee7194e0fc1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (39.0.1)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 39.0.1\n",
            "    Uninstalling setuptools-39.0.1:\n",
            "      Successfully uninstalled setuptools-39.0.1\n",
            "Successfully installed setuptools-65.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "0NG-rgNN-qF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI8qNTVA-yYk",
        "outputId": "0fc53e51-5ee9-4563-bf17-bb05bba143db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Using cached PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.5)\n",
            "Collecting tqdm>=4.27\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (21.3)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.0/770.0 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
            "Installing collected packages: tokenizers, tqdm, regex, pyyaml, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 pyyaml-6.0 regex-2022.10.31 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.24.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJblQjjo-ya4",
        "outputId": "34592912-d857-4f39-8d6e-fa874366b742"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py\n",
            "       [-h]\n",
            "       [-en EPOCHS_NB]\n",
            "       [-bz BATCH_SIZE]\n",
            "       [-bm]\n",
            "       [-mp MODEL_PATH]\n",
            "       [-cw CUSTOM_WEIGHTS]\n",
            "       [-cs CONTEXT_SIZE]\n",
            "       [-cp CONLL_PERCENTAGE]\n",
            "       [-koc [KEEP_ONLY_CLASSES ...]]\n",
            "       [-tmp TEST_METRICS_PATH]\n",
            "       [-das DATA_AUG_STRATEGIES]\n",
            "       [-daf DATA_AUG_FREQUENCIES]\n",
            "       [-dam DATA_AUG_METHOD]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  -en EPOCHS_NB, --epochs-nb EPOCHS_NB\n",
            "  -bz BATCH_SIZE, --batch-size BATCH_SIZE\n",
            "  -bm, --batch-mode\n",
            "  -mp MODEL_PATH, --model-path MODEL_PATH\n",
            "  -cw CUSTOM_WEIGHTS, --custom-weights CUSTOM_WEIGHTS\n",
            "    Custom\n",
            "    class\n",
            "    weights, as\n",
            "    a json\n",
            "    dictionay.\n",
            "    Exemple :\n",
            "    python\n",
            "    train.py\n",
            "    -cw\n",
            "    '{\"B-PER\":\n",
            "    2}'\n",
            "    (default:\n",
            "    None)\n",
            "  -cs CONTEXT_SIZE, --context-size CONTEXT_SIZE\n",
            "  -cp CONLL_PERCENTAGE, --conll-percentage CONLL_PERCENTAGE\n",
            "    percentage\n",
            "    of conll to\n",
            "    use for\n",
            "    training,\n",
            "    between 0\n",
            "    and 1 (who\n",
            "    would use 0\n",
            "    though ?)\n",
            "    (default:\n",
            "    1.0)\n",
            "  -koc [KEEP_ONLY_CLASSES ...], --keep-only-classes [KEEP_ONLY_CLASSES ...]\n",
            "    A list of\n",
            "    classes to\n",
            "    keep at\n",
            "    training\n",
            "    time,\n",
            "    separated\n",
            "    by spaces.\n",
            "    Exemple :\n",
            "    'PER ORG'\n",
            "    (default:\n",
            "    None)\n",
            "  -tmp TEST_METRICS_PATH, --test-metrics-path TEST_METRICS_PATH\n",
            "  -das DATA_AUG_STRATEGIES, --data-aug-strategies DATA_AUG_STRATEGIES\n",
            "    a json\n",
            "    dictionary\n",
            "    mapping a\n",
            "    NER class\n",
            "    to a list\n",
            "    of\n",
            "    replacement\n",
            "    strategies\n",
            "    (available\n",
            "    strategies\n",
            "    : ['conll',\n",
            "    'wgold', 'c\n",
            "    apitalizati\n",
            "    on', 'morro\n",
            "    wind',\n",
            "    'french', '\n",
            "    word_names'\n",
            "    , 'dekker_f\n",
            "    antasy', 't\n",
            "    he_elder_sc\n",
            "    rolls'])\n",
            "    (default:\n",
            "    {})\n",
            "  -daf DATA_AUG_FREQUENCIES, --data-aug-frequencies DATA_AUG_FREQUENCIES\n",
            "    a json\n",
            "    dictionary\n",
            "    mapping a\n",
            "    NER class\n",
            "    to a list\n",
            "    of\n",
            "    frequencies\n",
            "    for the\n",
            "    given\n",
            "    replacement\n",
            "    strategies,\n",
            "    in order\n",
            "    (default:\n",
            "    {})\n",
            "  -dam DATA_AUG_METHOD, --data-aug-method DATA_AUG_METHOD\n",
            "    augmentatio\n",
            "    n method.\n",
            "    One of\n",
            "    'standard',\n",
            "    'replace'or\n",
            "    'balance_up\n",
            "    sample'\n",
            "    (default:\n",
            "    standard)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py\\\n",
        "       --epochs-nb 2\\\n",
        "       --batch-size 6\\\n",
        "       --context-size 1\\\n",
        "       --data-aug-strategies '{\"PER\": [\"word_names\"]}'\\\n",
        "       --data-aug-frequencies '{\"PER\": [0.1]}'\\\n",
        "       --model-path augmented_model.pth"
      ],
      "metadata": {
        "id": "od3i2Dw6--nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py\\\n",
        "       --epochs-nb 2\\\n",
        "       --batch-size 6\\\n",
        "       --context-size 1\\\n",
        "       --data-aug-strategies '{\"PER\": [\"word_names\"]}'\\\n",
        "       --data-aug-frequencies '{\"PER\": [1.0]}'\\\n",
        "       --model-path augmented_model.pth"
      ],
      "metadata": {
        "id": "9KfDROpWAiE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncOXhONY-ytV",
        "outputId": "6d4628b6-1220-4598-9a2b-ff2fe1811c57"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running with config : \n",
            "\u001b[1m{\u001b[0m\n",
            "    \u001b[32m'epochs_nb'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
            "    \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
            "    \u001b[32m'batch_mode'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "    \u001b[32m'model_path'\u001b[0m: \u001b[32m'./ner_model'\u001b[0m,\n",
            "    \u001b[32m'custom_weights'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'context_size'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
            "    \u001b[32m'conll_percentage'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
            "    \u001b[32m'keep_only_classes'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'test_metrics_path'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'data_aug_strategies'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
            "    \u001b[32m'data_aug_frequencies'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
            "    \u001b[32m'data_aug_method'\u001b[0m: \u001b[32m'standard'\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n",
            "Downloading: 100% 29.0/29.0 [00:00<00:00, 19.5kB/s]\n",
            "Downloading: 100% 213k/213k [00:00<00:00, 859kB/s]\n",
            "Downloading: 100% 436k/436k [00:00<00:00, 1.40MB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 531kB/s]\n",
            "Downloading: 100% 436M/436M [00:04<00:00, 94.0MB/s]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0% 0/3747 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "loss : 0.002: 100% 3747/3747 [05:01<00:00, 12.43it/s]\n",
            "epoch mean loss : 0.135\n",
            "  0% 0/867 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 867/867 [00:11<00:00, 72.80it/s]\n",
            "{\n",
            "    \"validation precision\": 0.9287878787878788,\n",
            "    \"validation recall\": 0.928475260854931,\n",
            "    \"validation f1\": 0.9286315435111935\n",
            "}\n",
            "loss : 0.001: 100% 3747/3747 [05:03<00:00, 12.33it/s]\n",
            "epoch mean loss : 0.048\n",
            "100% 867/867 [00:12<00:00, 72.03it/s]\n",
            "{\n",
            "    \"validation precision\": 0.9365503422942061,\n",
            "    \"validation recall\": 0.94395826321104,\n",
            "    \"validation f1\": 0.9402397116754673\n",
            "}\n",
            "loss : 0.002: 100% 3747/3747 [05:02<00:00, 12.38it/s]\n",
            "epoch mean loss : 0.031\n",
            "100% 867/867 [00:12<00:00, 67.40it/s]\n",
            "{\n",
            "    \"validation precision\": 0.9309658148025224,\n",
            "    \"validation recall\": 0.9441265567149109,\n",
            "    \"validation f1\": 0.9375\n",
            "}\n",
            "loss : 0.015: 100% 3747/3747 [05:01<00:00, 12.44it/s]\n",
            "epoch mean loss : 0.023\n",
            "100% 867/867 [00:11<00:00, 72.65it/s]\n",
            "{\n",
            "    \"validation precision\": 0.921285667431945,\n",
            "    \"validation recall\": 0.9454729047458769,\n",
            "    \"validation f1\": 0.9332225913621263\n",
            "}\n",
            "loss : 0.016: 100% 3747/3747 [05:03<00:00, 12.36it/s]\n",
            "epoch mean loss : 0.017\n",
            "100% 867/867 [00:11<00:00, 72.34it/s]\n",
            "{\n",
            "    \"validation precision\": 0.9285832642916322,\n",
            "    \"validation recall\": 0.9431167956916863,\n",
            "    \"validation f1\": 0.9357936044084496\n",
            "}\n",
            "  0% 0/921 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 921/921 [00:12<00:00, 75.68it/s]\n",
            "test metrics : \n",
            "\u001b[1m{\u001b[0m\n",
            "    \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.9302325581395349\u001b[0m,\n",
            "    \u001b[32m'recall'\u001b[0m: \u001b[1;36m0.9400123685837971\u001b[0m,\n",
            "    \u001b[32m'f1'\u001b[0m: \u001b[1;36m0.9350968932636111\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10% of data augmentation"
      ],
      "metadata": {
        "id": "BoyHx5-1ET-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py\\\n",
        "       --epochs-nb 2\\\n",
        "       --batch-size 6\\\n",
        "       --context-size 1\\\n",
        "       --data-aug-strategies '{\"PER\": [\"word_names\"]}'\\\n",
        "       --data-aug-frequencies '{\"PER\": [0.1]}'\\\n",
        "       --model-path augmented_model.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZqiQHywBFFB",
        "outputId": "2d03e7cf-c576-4c9a-dc94-8ff2d6f7e1df"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running with config : \n",
            "\u001b[1m{\u001b[0m\n",
            "    \u001b[32m'epochs_nb'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
            "    \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
            "    \u001b[32m'batch_mode'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "    \u001b[32m'model_path'\u001b[0m: \u001b[32m'augmented_model.pth'\u001b[0m,\n",
            "    \u001b[32m'custom_weights'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'context_size'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
            "    \u001b[32m'conll_percentage'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
            "    \u001b[32m'keep_only_classes'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'test_metrics_path'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'data_aug_strategies'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"PER\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"word_names\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
            "    \u001b[32m'data_aug_frequencies'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"PER\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m0.1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
            "    \u001b[32m'data_aug_method'\u001b[0m: \u001b[32m'standard'\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0% 0/2748 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "loss : 0.003: 100% 2748/2748 [06:30<00:00,  7.03it/s]\n",
            "epoch mean loss : 0.093\n",
            "  0% 0/578 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 578/578 [00:20<00:00, 28.42it/s]\n",
            "{\n",
            "    \"validation precision\": 0.9342433827201598,\n",
            "    \"validation recall\": 0.9444631437226523,\n",
            "    \"validation f1\": 0.9393254665662398\n",
            "}\n",
            "loss : 0.007: 100% 2748/2748 [06:31<00:00,  7.03it/s]\n",
            "epoch mean loss : 0.020\n",
            "100% 578/578 [00:19<00:00, 28.95it/s]\n",
            "{\n",
            "    \"validation precision\": 0.941314161511453,\n",
            "    \"validation recall\": 0.9474924267923258,\n",
            "    \"validation f1\": 0.9443931896334815\n",
            "}\n",
            "  0% 0/614 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 614/614 [00:19<00:00, 31.55it/s]\n",
            "test metrics : \n",
            "\u001b[1m{\u001b[0m\n",
            "    \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.9563046192259675\u001b[0m,\n",
            "    \u001b[32m'recall'\u001b[0m: \u001b[1;36m0.9474335188620903\u001b[0m,\n",
            "    \u001b[32m'f1'\u001b[0m: \u001b[1;36m0.9518484001242622\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#100% of data augmentation"
      ],
      "metadata": {
        "id": "BBmEMy5YEXkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py\\\n",
        "       --epochs-nb 2\\\n",
        "       --batch-size 6\\\n",
        "       --context-size 1\\\n",
        "       --data-aug-strategies '{\"PER\": [\"word_names\"]}'\\\n",
        "       --data-aug-frequencies '{\"PER\": [1.0]}'\\\n",
        "       --model-path augmented_model.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wff-ioLWEZZh",
        "outputId": "8817e84b-63d0-4a4c-e3b8-823db03c9458"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running with config : \n",
            "\u001b[1m{\u001b[0m\n",
            "    \u001b[32m'epochs_nb'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
            "    \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
            "    \u001b[32m'batch_mode'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "    \u001b[32m'model_path'\u001b[0m: \u001b[32m'augmented_model.pth'\u001b[0m,\n",
            "    \u001b[32m'custom_weights'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'context_size'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
            "    \u001b[32m'conll_percentage'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
            "    \u001b[32m'keep_only_classes'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'test_metrics_path'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[32m'data_aug_strategies'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"PER\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"word_names\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
            "    \u001b[32m'data_aug_frequencies'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"PER\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m1.0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
            "    \u001b[32m'data_aug_method'\u001b[0m: \u001b[32m'standard'\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0% 0/4996 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "loss : 0.002: 100% 4996/4996 [10:40<00:00,  7.81it/s]\n",
            "epoch mean loss : 0.068\n",
            "  0% 0/578 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 578/578 [00:19<00:00, 29.00it/s]\n",
            "{\n",
            "    \"validation precision\": 0.9335872805564757,\n",
            "    \"validation recall\": 0.9486704813194211,\n",
            "    \"validation f1\": 0.9410684474123541\n",
            "}\n",
            "loss : 0.001: 100% 4996/4996 [10:39<00:00,  7.81it/s]\n",
            "epoch mean loss : 0.014\n",
            "100% 578/578 [00:19<00:00, 28.98it/s]\n",
            "{\n",
            "    \"validation precision\": 0.943267145002503,\n",
            "    \"validation recall\": 0.9513631773813531,\n",
            "    \"validation f1\": 0.9472978634268958\n",
            "}\n",
            "  0% 0/614 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 614/614 [00:19<00:00, 31.56it/s]\n",
            "test metrics : \n",
            "\u001b[1m{\u001b[0m\n",
            "    \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.9130434782608695\u001b[0m,\n",
            "    \u001b[32m'recall'\u001b[0m: \u001b[1;36m0.961038961038961\u001b[0m,\n",
            "    \u001b[32m'f1'\u001b[0m: \u001b[1;36m0.9364266345284724\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "8SM0woP5FAwG",
        "outputId": "90e78dd7-dd64-4a45-d305-c09e077958a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-bacb78b82c09>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for aug in conll wgold morrowind dekker:\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jgBjPdobfJ3X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DRMOfQnjQLt0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}